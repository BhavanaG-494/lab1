#!/usr/bin/env python
# coding: utf-8

# In[1]:


#1


# In[2]:


pip install tensorflow


# In[4]:


pip install keras


# In[5]:


from nltk.tokenize import sent_tokenize,word_tokenize


# In[6]:


import warnings
warnings.filterwarnings(action='ignore')


# In[7]:


import gensim
from gensim.models import Word2Vec


# In[12]:


sample = open("C:\\Users\\Student\\Desktop\\alice.txt", "r", encoding="utf-8")
s = sample.read()


# In[13]:


f=s.replace("\n"," ")


# In[14]:


data=[]


# In[17]:


for i in sent_tokenize(f):
    temp=[]
    for j in word_tokenize(i):
        temp.append(j.lower())
    data.append(temp)


# In[16]:


import nltk
nltk.download('punkt')


# In[19]:


model1=gensim.models.Word2Vec(data,min_count=1,vector_size=100,window=5)


# In[20]:


print("cosine similarity between 'alice'"+"and 'wonderland'-CBOW:",model1.wv.similarity('alice','wonderland'))


# In[21]:


print("cosine similarity between 'alice'"+"and 'machines'-CBOW:",model1.wv.similarity('alice','machines'))


# In[22]:


model2=gensim.models.Word2Vec(data,min_count=1,vector_size=100,window=5,sg=1)


# In[24]:


print("cosine similarity between 'alice'"+"and 'wonderland'-Skip Gram:",model2.wv.similarity('alice','wonderland'))


# In[25]:


print("cosine similarity between 'alice'"+"and 'machines'-Skip Gram:",model2.wv.similarity('alice','machines'))


# In[ ]:




